{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Abbaszadeh/CNN/blob/main/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "HUWLQTR6rZN7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root='data/', download=True, transform=ToTensor())\n",
        "len(dataset)\n",
        "dataset[10]\n",
        "\n",
        "image, label=dataset[0]\n",
        "\n",
        "train_ds, val_ds=random_split(dataset, [50000,10000])\n",
        "\n",
        "len(train_ds), len(val_ds)\n",
        "\n",
        "batch_size=128\n",
        "\n",
        "train_loader=DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True )\n",
        "val_loader=DataLoader(val_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True )\n",
        "\n",
        "for images, _ in train_loader:\n",
        "    print ('image.shape:/n', image.shape)\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(make_grid(images, nrow=16).permute((1,2,0))) #what it does is that it take a batch of images and convert them into a single image.\n",
        "    break\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print ('image.shape:', images.shape)\n",
        "    inputs=images.reshape(-1, 784)\n",
        "    print('inputs.shape:', inputs.shape)\n",
        "    break\n",
        ""
      ],
      "metadata": {
        "id": "Ta9Knp1erboI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=inputs.shape[-1] #784\n",
        "hidden_size=32\n",
        "\n",
        "#layer1 generates wights and biases\n",
        "layer1=nn.Linear(input_size, hidden_size) #(784, 32)\n",
        "#inputs.shape\n",
        "\n",
        "#layer1 contains wight and biases. so, we need to insert the images to layer1. the outputs essentially should be [128,32]\n",
        "layer1_outputs=layer1(inputs)\n",
        "print('layer1_outputs.shape:', layer1_outputs.shape)\n",
        "\n",
        "layer1_outputs_direct= inputs @ layer1.weight.t() + layer1.bias\n",
        "layer1_outputs_direct.shape\n",
        "\n",
        "#torch.allclose is to compare the values of output directly calculated from the nn.linear and direct computation\n",
        "torch.allclose(layer1_outputs, layer1_outputs_direct, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Ggk0fHvUA7",
        "outputId": "92597af0-6b94-4062-b466-91518dce01be"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer1_outputs.shape: torch.Size([128, 32])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation function\n",
        "#Rectified linear unit (ReLU): relu(x)=max(0,x), see example below\n",
        "\n",
        "F.relu(torch.tensor([[1,-1,0],[-0.1,.2,-.3]]))\n",
        "\n",
        "\n",
        "relu_outputs=F.relu(layer1_outputs)  #[128, 32]\n",
        "\n",
        "relu_outputs.shape\n",
        "\n",
        "output_size=10\n",
        "\n",
        "layer2=nn.Linear(hidden_size, output_size) #[32 10]\n",
        "\n",
        "layer2_outputs= layer2(relu_outputs)  #[128 32] x [32 10] + [128 10]= [128 10]  10 outputs for each image\n",
        "#print (layer2_outputs.shape)\n",
        "\n",
        "F.cross_entropy(layer2_outputs, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oph-S1OgvWnC",
        "outputId": "961e2edc-dc42-4b0e-9a78-567fa1abd415"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3425, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "    \"\"\"Feedforward neural network with 1 hidden layer\"\"\"\n",
        "    def __init__(self, in_size, hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        #hidden layer\n",
        "        self.linear1= nn.Linear(in_size, hidden_size)\n",
        "        #output layer\n",
        "        self.linear2= nn.Linear(hidden_size, out_size)\n",
        "\n",
        "\n",
        "    def forward(self, xb):\n",
        "        # Flatten the image tensor\n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "        # Get intermdeiate outputs using hidden layer\n",
        "        out = self.linear1(xb)\n",
        "        # Apply activation function\n",
        "        out=F.relu(out)\n",
        "        # Get prediction using output layer\n",
        "        out=self.linear2(out)\n",
        "        return out\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "jsy70nK1vZtQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds= torch.max(outputs, dim=1)\n",
        "    return torch.tensor (torch.sum (preds == labels).item()/len(preds))"
      ],
      "metadata": {
        "id": "467NFQKRvcTP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=748\n",
        "hidden_size=32\n",
        "num_classes=10\n",
        "\n",
        "model=MnistModel(input_size, hidden_size=32, out_size=num_classes)\n",
        "\n",
        "\n",
        "for t in model.parameters():\n",
        "    print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dRx4cAmvfGr",
        "outputId": "c767ae64-a8eb-43fc-fcd4-9c863f945fb0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 748])\n",
            "torch.Size([32])\n",
            "torch.Size([10, 32])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGUvUhTHvmX8",
        "outputId": "43f012e7-03c2-431e-f458-5ae713c932c3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PEPxgW8wvm3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l01c01_introduction_to_colab_and_python.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}