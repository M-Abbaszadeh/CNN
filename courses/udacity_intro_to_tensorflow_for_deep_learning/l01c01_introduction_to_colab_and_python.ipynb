{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Abbaszadeh/CNN/blob/main/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "HUWLQTR6rZN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root='data/', download=True, transform=ToTensor())\n",
        "len(dataset)\n",
        "dataset[10]\n",
        "\n",
        "image, label=dataset[0]\n",
        "\n",
        "train_ds, val_ds=random_split(dataset, [50000,10000])\n",
        "\n",
        "len(train_ds), len(val_ds)\n",
        "\n",
        "batch_size=128\n",
        "\n",
        "train_loader=DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True )\n",
        "val_loader=DataLoader(val_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True )\n",
        "\n",
        "for images, _ in train_loader:\n",
        "    print ('image.shape:/n', image.shape)\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(make_grid(images, nrow=16).permute((1,2,0))) #what it does is that it take a batch of images and convert them into a single image.\n",
        "    break\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print ('image.shape:', images.shape)\n",
        "    inputs=images.reshape(-1, 784)\n",
        "    print('inputs.shape:', inputs.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "Ta9Knp1erboI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=inputs.shape[-1] #784\n",
        "hidden_size=32\n",
        "\n",
        "#layer1 generates wights and biases\n",
        "layer1=nn.Linear(input_size, hidden_size) #(784, 32)\n",
        "#inputs.shape\n",
        "\n",
        "#layer1 contains wight and biases. so, we need to insert the images to layer1. the outputs essentially should be [128,32]\n",
        "layer1_outputs=layer1(inputs)\n",
        "print('layer1_outputs.shape:', layer1_outputs.shape)\n",
        "\n",
        "layer1_outputs_direct= inputs @ layer1.weight.t() + layer1.bias\n",
        "layer1_outputs_direct.shape\n",
        "\n",
        "#torch.allclose is to compare the values of output directly calculated from the nn.linear and direct computation\n",
        "torch.allclose(layer1_outputs, layer1_outputs_direct, 1e-3)"
      ],
      "metadata": {
        "id": "l2Ggk0fHvUA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation function\n",
        "#Rectified linear unit (ReLU): relu(x)=max(0,x), see example below\n",
        "\n",
        "F.relu(torch.tensor([[1,-1,0],[-0.1,.2,-.3]]))\n",
        "\n",
        "\n",
        "relu_outputs=F.relu(layer1_outputs)  #[128, 32]\n",
        "\n",
        "relu_outputs.shape\n",
        "\n",
        "output_size=10\n",
        "\n",
        "layer2=nn.Linear(hidden_size, output_size) #[32 10]\n",
        "\n",
        "layer2_outputs= layer2(relu_outputs)  #[128 32] x [32 10] + [128 10]= [128 10]  10 outputs for each image\n",
        "#print (layer2_outputs.shape)\n",
        "\n",
        "F.cross_entropy(layer2_outputs, labels)"
      ],
      "metadata": {
        "id": "Oph-S1OgvWnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "    \"\"\"Feedforward neural network with 1 hidden layer\"\"\"\n",
        "    def __init__(self, in_size, hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        #hidden layer\n",
        "        self.linear1= nn.Linear(in_size, hidden_size)\n",
        "        #output layer\n",
        "        self.linear2= nn.Linear(hidden_size, out_size)\n",
        "\n",
        "\n",
        "    def forward(self, xb):\n",
        "        # Flatten the image tensor\n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "        # Get intermdeiate outputs using hidden layer\n",
        "        out = self.linear1(xb)\n",
        "        # Apply activation function\n",
        "        out=F.relu(out)\n",
        "        # Get prediction using output layer\n",
        "        out=self.linear2(out)\n",
        "        return out\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "jsy70nK1vZtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds= torch.max(outputs, dim=1)\n",
        "    return torch.tensor (torch.sum (preds == labels).item()/len(preds))"
      ],
      "metadata": {
        "id": "467NFQKRvcTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=784\n",
        "hidden_size=32\n",
        "num_classes=10\n",
        "\n",
        "model=MnistModel(input_size, hidden_size=32, out_size=num_classes)\n",
        "\n",
        "\n",
        "for t in model.parameters():\n",
        "    print(t.shape)"
      ],
      "metadata": {
        "id": "_dRx4cAmvfGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "pGUvUhTHvmX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "      return torch.device('cuda')\n",
        "    else:\n",
        "      return torch.device('CPU')\n",
        "\n",
        "device =get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "PEPxgW8wvm3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "metadata": {
        "id": "4nd49U92zZ6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "jgQAVFAz0Vsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_loader, device)\n",
        "valid_dl = DeviceDataLoader(val_loader, device)"
      ],
      "metadata": {
        "id": "1eR0Cw_w4hD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "ii1_9Iwl9JV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = [] # for recording epoch-wise results\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Training Phase\n",
        "        for batch in train_loader:\n",
        "            batch = to_device(batch, next(model.parameters()).device) # Move batch to device\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "saIfhI4Q4z5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=MnistModel(input_size, hidden_size=hidden_size, out_size=num_classes)\n",
        "to_device(model, device)"
      ],
      "metadata": {
        "id": "OGHroTlK6zHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=[evaluate(model, valid_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "wht7V_xc695D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history =[]\n",
        "history += fit(5, 0.5, model, train_dl, valid_dl)"
      ],
      "metadata": {
        "id": "GRyWCiZS7Yle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history += fit(5, 0.1, model, train_dl, valid_dl)"
      ],
      "metadata": {
        "id": "er3U5cnXyAXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses= [x['val_loss'] for x in history]\n",
        "plt.plot(losses, '-x')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "accuracies= [x['val_acc'] for x in history]\n",
        "plt.plot(accuracies, '-x')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');\n"
      ],
      "metadata": {
        "id": "lRfLyA3lzGrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define test dataset\n",
        "\n",
        "test_dataset=MNIST(root='data/', train=False, transform=ToTensor())\n",
        "\n",
        "def predic_image(img, model):\n",
        "    xb=to_device(img.unsqueeze(0), device)\n",
        "    yb=model(xb)\n",
        "    _, preds=torch.max(yb, dim=1)\n",
        "    return preds[0].item()\n"
      ],
      "metadata": {
        "id": "aLG8odxFzyWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label=test_dataset[193]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predic_image(img, model))"
      ],
      "metadata": {
        "id": "3CEtXtfu2FMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader= DeviceDataLoader(DataLoader(test_dataset, batch_size=256), device)\n",
        "result=evaluate(model, test_loader)\n",
        "result"
      ],
      "metadata": {
        "id": "06TMfO672Og5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JmA3R83B4q-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l01c01_introduction_to_colab_and_python.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}